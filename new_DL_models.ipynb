{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2fbdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ce719",
   "metadata": {},
   "source": [
    "### Improved Neural Network\n",
    "The following model is the base for all other models created by me.\n",
    "It provides following functions:\n",
    "##### compile\n",
    "Provides essential parameters for training the model.\n",
    "###### Parameters:\n",
    "- loss_function\n",
    "- optimizer\n",
    "- batch_size\n",
    "- device - device on which model is trained and makes predictions (using cuda for faster computations is highly recommended)\n",
    "\n",
    "##### train_on_data\n",
    "Trains the model. After the training is complited, it prints \"Done\" message.\n",
    "###### Parameters:\n",
    "- train_dataset - PyTorch's Dataset for model training\n",
    "- test_dataset - PyTorch's Dataset for model validation\n",
    "- n_epochs - number of epochs for the data to be trained\n",
    "- print_step - frequency of printing loss for the current batch\n",
    "\n",
    "##### predict\n",
    "Makes prediction for given data.\n",
    "##### Parameters:\n",
    "- test_data - PyTorch's Dataset containing data our model is to use to make prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62326792",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedNeuralNetwork(nn.Module):\n",
    "    def __train_loop(self, dataloader):\n",
    "        self.train()\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            predictions = self(X)\n",
    "            loss = self.loss_function(\n",
    "                predictions, \n",
    "                torch.unsqueeze(y, 1)\n",
    "            )\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "    def __test_loop(self, dataloader):\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for X, y in dataloader:\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                predictions = self(X)\n",
    "                test_loss += self.loss_function(\n",
    "                    predictions, \n",
    "                    torch.unsqueeze(y, 1)\n",
    "                )\n",
    "        # Dividing test_loss by number of batches\n",
    "        test_loss /= len(dataloader)\n",
    "        return test_loss\n",
    "    \n",
    "    def compile(self, loss_function, optimizer, batch_size, device):\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optimizer\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def train_on_data(self, train_dataset, test_dataset, n_epochs, print_step = 1):\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True\n",
    "        )\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size = self.batch_size,\n",
    "            shuffle = True\n",
    "        )\n",
    "\n",
    "        self.to(self.device)\n",
    "        for i in range(n_epochs):\n",
    "            self.__train_loop(train_dataloader)\n",
    "            test_loss = self.__test_loop(test_dataloader)\n",
    "            if (i + 1) % print_step == 0:\n",
    "              print(\"Epoch\", i, \", loss:\", test_loss)\n",
    "        print(\"Done.\")\n",
    "        self.to('cpu')\n",
    "\n",
    "\n",
    "    def predict(self, test_dataset):\n",
    "        self.to(self.device)\n",
    "        test_dataset = test_dataset.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            predictions = self(test_dataset)\n",
    "        self.to('cpu')\n",
    "        test_dataset = test_dataset.to('cpu')\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663a17",
   "metadata": {},
   "source": [
    "### Simplified Neural Network\n",
    "The following model simplifies the process of creating neural network. To create the model, one has to provide following paramters:\n",
    "- input_shape - the input's shape\n",
    "- layer_sizes - list of numer of neurons in each layer\n",
    "The the creates a series of layers of neurons connected by PyTorch's GELU activation function.\n",
    "I used GELU instead of ReLU, because it was proved to yield better results, while not decreasing the computational time significantly (also it has nice robabilistic interpretation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e61050",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplifiedNeuralNetwork(ImprovedNeuralNetwork):\n",
    "    def __init__(self, input_shape, layer_sizes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_shape, layer_sizes[0]),\n",
    "        )\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            self.linear_relu_stack.append(nn.GELU())\n",
    "            self.linear_relu_stack.append(\n",
    "                nn.Linear(layer_sizes[i - 1], layer_sizes[i])\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7498979",
   "metadata": {},
   "source": [
    "### BinaryRegressor\n",
    "This is basically SimplifiedNeuralNetwork, but after passing data through the neural network, it passes it additionally through the PyTorch's sigmoid layer, so that each number it produces is in range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ba80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRegressor(SimplifiedNeuralNetwork):\n",
    "    def __init__(self, input_shape, layer_sizes):\n",
    "        super().__init__(input_shape, layer_sizes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = super().forward(x)\n",
    "        return self.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6054d6fb",
   "metadata": {},
   "source": [
    "### Usage example\n",
    "\n",
    "Below I present an example of how to use the BinaryRegressor class (the presentation encompasses all methods that were added by me in other classes as well).\n",
    "For the presentation I will use data from Titanic Competition that was held on kaggle.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d96a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eff193",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "train_data.set_index('PassengerId', inplace = True)\n",
    "test_data.set_index('PassengerId', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1994a962",
   "metadata": {},
   "source": [
    "Below I perform simple preprocessing. I will not go into details as it is not the purpose of this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24180539",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Pclass', 'Parch', 'Fare']\n",
    "\n",
    "train_data.dropna(axis = 'index', subset = ['Survived'], inplace = True)\n",
    "y = train_data.Survived\n",
    "X_full = train_data.drop(['Survived'], axis = 'columns')[features]\n",
    "X_test = test_data[features]\n",
    "\n",
    "random_subset = random.sample(range(1, train_data.shape[0]), train_data.shape[0] // 5)\n",
    "X_valid, y_valid = X_full.loc[random_subset, :], y.loc[random_subset]\n",
    "X_train, y_train = X_full.drop(random_subset), y.drop(random_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb73c9",
   "metadata": {},
   "source": [
    "We specify the shape of our input, which in case of tabular data is simply number of columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58d043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ff44d",
   "metadata": {},
   "source": [
    "We define our model and set training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1666f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryRegressor(input_shape, [512, 256, 128, 64, 1])\n",
    "model.compile(\n",
    "    loss_function = nn.BCELoss(),  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 0.01),\n",
    "    batch_size = 64,\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0ee12",
   "metadata": {},
   "source": [
    "We create Datasets from our pd.Dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "785004b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(X_train.values, dtype = torch.float),\n",
    "    torch.tensor(y_train.values, dtype = torch.float)\n",
    ")\n",
    "\n",
    "valid_dataset = TensorDataset(\n",
    "    torch.tensor(X_valid.values, dtype = torch.float),\n",
    "    torch.tensor(y_valid.values, dtype = torch.float)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551e66c4",
   "metadata": {},
   "source": [
    "And finally we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2fcc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 , loss: tensor(0.6268, device='cuda:0')\n",
      "Epoch 1 , loss: tensor(0.6035, device='cuda:0')\n",
      "Epoch 2 , loss: tensor(0.5930, device='cuda:0')\n",
      "Epoch 3 , loss: tensor(0.5808, device='cuda:0')\n",
      "Epoch 4 , loss: tensor(0.5773, device='cuda:0')\n",
      "Epoch 5 , loss: tensor(0.6631, device='cuda:0')\n",
      "Epoch 6 , loss: tensor(0.5841, device='cuda:0')\n",
      "Epoch 7 , loss: tensor(0.5663, device='cuda:0')\n",
      "Epoch 8 , loss: tensor(0.5830, device='cuda:0')\n",
      "Epoch 9 , loss: tensor(0.5631, device='cuda:0')\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "model.train_on_data(train_dataset, valid_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3af18",
   "metadata": {},
   "source": [
    "After training the model, we can make some predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74fbafaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2300, 0.2311, 0.4035, 0.2370, 0.4093, 0.2512, 0.2297, 0.4550, 0.2303,\n",
       "        0.4401], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities_predictions = model.predict(torch.tensor(X_test.values, dtype = torch.float))\n",
    "probabilities_predictions[0:10].squeeze()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
